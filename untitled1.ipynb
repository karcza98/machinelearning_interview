{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1dcKJlYxdcQsGuPh5iPlGbXabLsZCmBOM",
      "authorship_tag": "ABX9TyNTexSya2HLf/9wEZjCxnF2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karcza98/machinelearning_interview/blob/main/untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rank-bm25\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "GcnoieFFaWCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas.core.frame import DataFrame\n",
        "from rank_bm25 import BM25Okapi\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "eOarzj4Oq9Cf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/2020s-movies.csv')"
      ],
      "metadata": {
        "id": "GTW2rOt6Y8ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pandas dataframe listákra bontása\n",
        "rows = [list(row) for _, row in data.iterrows()]\n",
        "\n",
        "# Tokenizáló függvény\n",
        "def tokenize_nested_list(lst):\n",
        "    tokenized_list = []\n",
        "    for sub_list in lst:\n",
        "        tokenized_sub_list = []\n",
        "        for item in sub_list:\n",
        "            if isinstance(item, str):\n",
        "                tokenized_sub_list.extend(word_tokenize(item.lower()))\n",
        "            else:\n",
        "                tokenized_sub_list.append(item)\n",
        "        tokenized_list.append(tokenized_sub_list)\n",
        "    return tokenized_list"
      ],
      "metadata": {
        "id": "Ogq3LgWLu3FV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizálás\n",
        "tokenized_list = tokenize_nested_list(rows)\n",
        "# BM25 modell létrehozása a tokenizált dokumentumok alapján\n",
        "bm25 = BM25Okapi(tokenized_list)"
      ],
      "metadata": {
        "id": "aczqBGYDc7hZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ranked(data, user_question):\n",
        "  # Keresési lekérdezés tokenizálása szavakra\n",
        "  query_tokens = user_question.split(\" \")\n",
        "  # Dokumentumok rangsorolása a keresési lekérdezés alapján\n",
        "  doc_scores = list(bm25.get_scores(query_tokens))\n",
        "  #Legjobb 10 érték indexének kiválasztása\n",
        "  best_matches = np.argsort(doc_scores)[-10:]\n",
        "  #Dict készítés\n",
        "  data_dict = {}\n",
        "  for i in best_matches:\n",
        "    data_dict[data.loc[i]['title']]=data.loc[i]['plot']\n",
        "  return data_dict"
      ],
      "metadata": {
        "id": "M8ztKeMbr5t0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def LLM(data, user_question, data_dict):\n",
        "  # Betöltjük a Hugging Face Transformers question-answering modellt\n",
        "  qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n",
        "  # Kulcsok és értékek összefűzése\n",
        "  context = ' '.join([f'{key}: {value}' for key, value in data_dict.items()])\n",
        "  # Válasz generálása\n",
        "  answer = qa_pipeline(question=user_question, context=context)\n",
        "  return answer"
      ],
      "metadata": {
        "id": "5sh49HxPsxj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input a felhasználó kérdésének\n",
        "user_question = input(\"Please ask something about 2020s films: \")\n",
        "\n",
        "data_dict = ranked(data, user_question)\n",
        "answer = LLM(data, user_question, data_dict)\n",
        "\n",
        "# Válasz kiíráas\n",
        "print(\"The answer is:\", answer[\"answer\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRCRjhKnQOsk",
        "outputId": "eee02c71-d451-49d6-9c88-811ee2a83adb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please ask something about 2020s films: what is bullet train about?\n",
            "The answer is: the death of his wife\n"
          ]
        }
      ]
    }
  ]
}